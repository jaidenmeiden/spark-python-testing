{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos una sesión de spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark permite desde la creación de la sesión o contexto, indicar la cantidad de particiones que tendremos\n",
    "\n",
    "Para esto debemos de indicar con '[ ]'  en la indicación de master la cantidad total de particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Particionado\").master( \"local[5]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.range(0,20)\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método 'parallelize', permite la asignar manualmente la cantidad de particiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = spark.sparkContext.parallelize((0,20),6)\n",
    "rdd1.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deporte.csv\t deportistaError.csv  modelo_relacional.jpg\r\n",
      "deportista.csv\t evento.csv\t      paises.csv\r\n",
      "deportista2.csv  juegos.csv\t      resultados.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/jaidenmeiden/development/study/spark/spark-python-testing/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"files/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del mismo modo cuandore creamos un RDD o DF, podemos hacer esto.\n",
    "\n",
    "En el caso de los RDD se realiza de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddDesdeArchivo = spark \\\n",
    "    .sparkContext \\\n",
    "    .textFile(path+\"deporte.csv\",10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddDesdeArchivo.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una buena practica tener los archivos de datos particionados para una carga mas rápida y mejor administración.\n",
    "\n",
    "El método 'saveAsTextFile' permite almacenar los archivos, particionados o no, en un ruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddDesdeArchivo.saveAsTextFile(path+\"salidastexto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS    part-00001\tpart-00003  part-00005\tpart-00007  part-00009\r\n",
      "part-00000  part-00002\tpart-00004  part-00006\tpart-00008\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,Athletics\r\n",
      "8,Ice Hockey\r\n",
      "9,Swimming\r\n",
      "10,Badminton\r\n",
      "11,Sailing\r\n"
     ]
    }
   ],
   "source": [
    "# Visualizamos las primeras lineas de un archivo\n",
    "!head -n 5 /home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se muestra como cargar los multiples archivos en un mismo RDD.\n",
    "\n",
    "Esta operación tambien se puede realizar para DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.wholeTextFiles(path+\"salidastexto/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = rdd.mapValues(lambda x : x.split()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00000',\n",
       "  ['deporte_id,deporte',\n",
       "   '1,Basketball',\n",
       "   '2,Judo',\n",
       "   '3,Football',\n",
       "   '4,Tug-Of-War',\n",
       "   '5,Speed',\n",
       "   'Skating',\n",
       "   '6,Cross',\n",
       "   'Country',\n",
       "   'Skiing']),\n",
       " ('file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00001',\n",
       "  ['7,Athletics',\n",
       "   '8,Ice',\n",
       "   'Hockey',\n",
       "   '9,Swimming',\n",
       "   '10,Badminton',\n",
       "   '11,Sailing',\n",
       "   '12,Biathlon',\n",
       "   '13,Gymnastics',\n",
       "   '14,Art',\n",
       "   'Competitions']),\n",
       " ('file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00002',\n",
       "  ['15,Alpine',\n",
       "   'Skiing',\n",
       "   '16,Handball',\n",
       "   '17,Weightlifting',\n",
       "   '18,Wrestling',\n",
       "   '19,Luge',\n",
       "   '20,Water',\n",
       "   'Polo']),\n",
       " ('file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00003',\n",
       "  ['21,Hockey',\n",
       "   '22,Rowing',\n",
       "   '23,Bobsleigh',\n",
       "   '24,Fencing',\n",
       "   '25,Equestrianism',\n",
       "   '26,Shooting',\n",
       "   '27,Boxing',\n",
       "   '28,Taekwondo']),\n",
       " ('file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00004',\n",
       "  ['29,Cycling',\n",
       "   '30,Diving',\n",
       "   '31,Canoeing',\n",
       "   '32,Tennis',\n",
       "   '33,Modern',\n",
       "   'Pentathlon',\n",
       "   '34,Figure',\n",
       "   'Skating',\n",
       "   '35,Golf']),\n",
       " ('file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00005',\n",
       "  ['36,Softball',\n",
       "   '37,Archery',\n",
       "   '38,Volleyball',\n",
       "   '39,Synchronized',\n",
       "   'Swimming',\n",
       "   '40,Table',\n",
       "   'Tennis',\n",
       "   '41,Nordic',\n",
       "   'Combined']),\n",
       " ('file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00006',\n",
       "  ['42,Baseball',\n",
       "   '43,Rhythmic',\n",
       "   'Gymnastics',\n",
       "   '44,Freestyle',\n",
       "   'Skiing',\n",
       "   '45,Rugby',\n",
       "   'Sevens',\n",
       "   '46,Trampolining']),\n",
       " ('file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00007',\n",
       "  ['47,Beach',\n",
       "   'Volleyball',\n",
       "   '48,Triathlon',\n",
       "   '49,Ski',\n",
       "   'Jumping',\n",
       "   '50,Curling',\n",
       "   '51,Snowboarding',\n",
       "   '52,Rugby',\n",
       "   '53,Short',\n",
       "   'Track',\n",
       "   'Speed',\n",
       "   'Skating']),\n",
       " ('file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00008',\n",
       "  ['54,Skeleton',\n",
       "   '55,Lacrosse',\n",
       "   '56,Polo',\n",
       "   '57,Cricket',\n",
       "   '58,Racquets',\n",
       "   '59,Motorboating',\n",
       "   '60,Military',\n",
       "   'Ski',\n",
       "   'Patrol']),\n",
       " ('file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00009',\n",
       "  ['61,Croquet',\n",
       "   '62,Jeu',\n",
       "   'De',\n",
       "   'Paume',\n",
       "   '63,Roque',\n",
       "   '64,Alpinism',\n",
       "   '65,Basque',\n",
       "   'Pelota',\n",
       "   '66,Aeronautics'])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [l[0] for l in lista]\n",
    "l.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00000',\n",
       " 'file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00001',\n",
       " 'file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00002',\n",
       " 'file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00003',\n",
       " 'file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00004',\n",
       " 'file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00005',\n",
       " 'file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00006',\n",
       " 'file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00007',\n",
       " 'file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00008',\n",
       " 'file:/home/jaidenmeiden/development/study/spark/spark-python-testing/files/salidastexto/part-00009']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rddDesdeArchivo = spark \\\n",
    "    .sparkContext \\\n",
    "    .textFile(','.join(l),\n",
    "              10).map(lambda l : l.split(\",\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['deporte_id', 'deporte'],\n",
       " ['1', 'Basketball'],\n",
       " ['2', 'Judo'],\n",
       " ['3', 'Football'],\n",
       " ['4', 'Tug-Of-War'],\n",
       " ['5', 'Speed Skating'],\n",
       " ['6', 'Cross Country Skiing']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddDesdeArchivo.take(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jaidenmeiden/development/study/spark/spark-python-testing\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
